---
title: "Autonomous Resistor Sorter - Blog #2"
date: 2022-09-24


---


##MVLS UPDATE

With the solution to identifying colors being solved, it was time to optimize the model for its inference speed.
First, it would be useful to discuss the different approaches we tested to inference a model. The default method is to invoke the interpreter to find objects in the image that pass a certain accuracy threshold. This method is fast, but is not accurate for small objects such as resistors that only take up a partial amount of the image. The second method we used is tiling. Tiling is used for small object detection and it splits the image into sub tiles which are individually passed to the model and reconstructed into one big image later. This increases the accuracy for finding small objects by “zooming” into the objects but comes at a cost of inference speed. 
We found that using the default approach of finding objects in an image resulted in too little of an accuracy. Furthermore, we found tiling did highly increase our accuracy, however, the increase of the inference time was too large for our application. The problem with tiling for a single resistor is that since there is only one resistor in the frame, most of the tiles sent to the model are empty. If we had multiple resistors in the frame, then I could see the benefit of using tiling as more tiles would include resistors. To address this issue, we decided to make a second model dedicated specifically to detecting the resistor in the image. The model would find the resistor and return an image crop of only the resistor, thus “zooming” into the image and returning the information we care about without any useless background. The second model would then detect the resistor bands within the image crop. For this, we don’t need to implement tiling because the bands are not small objects within the frame anymore due to the crop. Finally, the band crops would be sent to our third and final model to determine the color of the bands as discussed in the last blog post. A pipeline of this approach can be seen below.

The resistor detecting model detects the resistor. Note: The label says band but it should say resistor, this was a simple labeling mistake made when labeling the data.4

The band detecting model only looks at the cropped image and returns the bands which are passed to the color detecting model.


Results from resistor detecting model:

Results from band detecting model:

The most important metric is the ‘AP’ or Average Precision. These values are acceptable for our model and will increase with further data collected. For these models, we only created a small dataset of 90 images as a proof of concept. Now that we know this approach works and is ideal, we will build our final dataset around it. 

Risks with approach:

The biggest risk with this approach comes from the hardware constraints we face by using a tiny edge device. Essentially, there is a limited amount of cache in the google coral. This cache is meant to hold the model parameters from one model. When we actively use two models, what happens is the model parameters from the first model are stored in cache, then kicked out when the second model is invoked. At this point, the second model parameters are moved to cache and this back and forth occurs as both model parameters want to be stored closely in cache. One approach to fix this problem is to co-compile the models. When you co-compile models, the device is aware and stores the first model’s parameters in cache and fills the rest of cache with the second model. The first model’s parameters do not get kicked out of cache when the second model is invoked, rather the second model’s parameters are fetched from memory instead. If we find that this hardware constraint is a problem, we will buy another google coral device and have each model run on each device.

Future steps;

Our future steps are to further build the dataset and to build a dataset for the third model. We already put time towards code on how to easily develop these datasets and it's now just about collecting the images and labeling them. This should take no longer than one day to finish. After that, it will be time to deploy the model onto the edge device which has already been developed and implemented before.
